{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28327116-1b69-4e4b-b15f-cfd35b8b2a4f",
   "metadata": {},
   "source": [
    "# Lab 2: Cosmological Rates, Star Formation Histories, & Detectability\n",
    "#### Mike Zevin, Monica Gallegos-Garcia\n",
    "\n",
    "Goals:\n",
    "\n",
    "* Learn how to calculate rate densities from a Transient Population\n",
    "* Understand how star formation history is convolved with the Transient Population to determine rates\n",
    "* Explore variations in star formation history and metallicity evolution assumptions\n",
    "* Apply detectability criteria to get observable rate predictions for transient sources\n",
    "\n",
    "___\n",
    "\n",
    "In this lab, we will piggyback off of the `TransientPopulation` class that we created in the previous lab to generate observable predictions. We will start by calculating rate densities for a particular transient population. These rate densities depend on assumptions for the star formation history (SFH) and metallicity evolution of the universe. There are significant uncertainties in both the SFH and metallicity evolution, so next we'll explore how to vary these and compare predictions for different assumptions. Lastly, we will dive into detectability. Each transient source has its own set of selection effects that depend on the detector. This detectability will turn our cosmological rate density into an actual detection rate. \n",
    "___\n",
    "\n",
    "## 1. Calculating Rate Densities from a Transient Population\n",
    "\n",
    "Let's first read in the Transient Population that we created in the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d891360-a6eb-4688-9e63-793c91af0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from posydon.popsyn.synthetic_population import TransientPopulation\n",
    "\n",
    "BBH_mergers = TransientPopulation(filename='BBH_mergers.h5', transient_name='BBH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d23b70-e1d3-4271-9b11-102a92fa61fb",
   "metadata": {},
   "source": [
    "The `Rates` class is another class in POSYDON. It is constructed from a particular `TransientPopulation`, and needs two things: \n",
    "- model weights that determine the contribution of each system in the `TransientPopulation` (in $M_\\odot^{-1}$)\n",
    "- a star formation history model\n",
    "\n",
    "The `Rates` class is a child class of the `TransientPopulation` class, which is in turn a child of the `Population` class, and therefore inherets information from these parent classes. \n",
    "\n",
    "We will first calculate cosmic weights associated with our transient population of BBH mergers. We specify the star formation history model parameters as a dictionary. For now we'll just use some basic parameter --- we'll get into variations in the star formation history model later in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c5061-9524-4ef3-91b5-8574e30b6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_model = {'SFR':'Madau+Fragos17',\n",
    "            'sigma':0.39,\n",
    "            'normalise':True,\n",
    "            'Z_min':0,\n",
    "            'Z_max':None}\n",
    "\n",
    "BBH_merger_rates = BBH_mergers.calculate_cosmic_weights('MadauFragos2017', model_weights='full_IMF', MODEL_in=SFH_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69f0c7-1395-4ae4-8250-f3791ebcfc81",
   "metadata": {},
   "source": [
    "These get saved as a new class instance with the same file name as the transient population (in our case, 'BBH_mergers.h5'). We can save multiple star formation history models with differing SFH identifiers. \n",
    "\n",
    "This new `rates` object we just created contains a few new things: \n",
    "- `z_birth`: the redshift and age of the universe at which we probe the star formation\n",
    "- `z_events`: the redshift at which an event takes place (so, the redshift that corresponds to $t_\\mathrm{birth} - t_\\mathrm{delay}$ where $t_\\mathrm{delay}$ is the delay time between stellar birth and the event, in our case BBH mergers); note that the values are NaN if the formation time + delay time is longer than the Hubble time\n",
    "- `weights`: the weight of the event based on the SFR, its metallicity distribution and evolution, and its weight in the population\n",
    "\n",
    "You can read in an instance of this class from our main file. Similar to before, we need to specifiy a transient name identifier (in our case, 'BBH') and a SFH identifier ('MadauFragos2017'). Once again, our main file can hold multiple different types of transients and SFH assumptions, and these instances are just called by specifying the associated `transient_name` and `SFH_identifier`. You can have as many transients and star formation histories in your population file as you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea523d3d-c1df-4bbf-aece-2607759e1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from posydon.popsyn.synthetic_population import Rates\n",
    "\n",
    "BBH_merger_rates = Rates(filename='BBH_mergers.h5', transient_name='BBH', SFH_identifier='MadauFragos2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3e9dd-ad4b-4675-9803-bad22c91d47a",
   "metadata": {},
   "source": [
    "You can directly work with the weights and the z_events to get events at specific redshifts. Let's take a second to look at the distribution of event masses at a few different redshifts: z=0, z=2, and z=10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f571b48-4313-41d4-9ec9-7efe35a10d2d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## MINI-EXERCISE:\n",
    "\n",
    "1. Write a piece of code that plots the primary mass distribution of BBHs from stars that were born at z=0.1, z=2, and z=10.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f743b19-8f00-410d-ab06-8c578cf2fc2c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "\n",
    "<b><summary>Hint (click to reveal):</summary></b>\n",
    "\n",
    "First get the index of the redshift bin from `BBH_merger_rates.z_birth`, then get the weights associated with this redshift index from `BBH_merger_rates.weights`, and lastly get the masses from `BBH_merger_rates.population`.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b335e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d32dc25-ee4a-4174-a371-82bef9f5158d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "\n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "    \n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for idx, z in enumerate([0.1, 2, 10]):\n",
    "    # first, find the redshift index closet to the one that we are looking for in z_birth\n",
    "    z_sample_idx = np.argwhere(BBH_merger_rates.z_birth['z'] > z)[0][0]\n",
    "\n",
    "    # next, find the weight associated with each systems that came from stars born at this redshift\n",
    "    weights = BBH_merger_rates.weights[z_sample_idx].values\n",
    "\n",
    "    # next, get the primary masses of the BHs from each system\n",
    "    masses = BBH_merger_rates.population['S1_mass'].values\n",
    "\n",
    "    # now, plot the weighted histogram\n",
    "    _ = ax.hist(masses, weights=weights, bins=28, range=(5,60), histtype='step', density=True, alpha=0.5, label='z = {:0.1f}'.format(z))\n",
    "\n",
    "plt.legend()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0cb3a-f323-4943-a835-51b9f9761f3f",
   "metadata": {},
   "source": [
    "From the `Rates` class you created, one can easily calculate and plot the rate density as a function of redshift for your transient event of choice using internal POSYDON class methods. This can be done for the full transient population, or by individual subchannels if you set `channels=True`. The index of the resultant dataframe is the redshift at which the rate is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1a361-371a-488b-a5a7-7f88a7698757",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBH_merger_rates.calculate_intrinsic_rate_density(channels=True)   # this can be called after it is calculated using rates.intrinsic_rate_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731d995-8559-4eee-87b8-ea9e87ae2059",
   "metadata": {},
   "source": [
    "Let's now plot the intrinsic rate evolution of your transient population with the SFH we assumed above using the `plot_intrinsic_rate` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d38103-ff80-499c-b5ac-63f97e0c918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBH_merger_rates.plot_intrinsic_rate(channels=True, xlim=(0,10), ylim=(1e-2,1e3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2d639-3bd6-4f3e-b6c7-98082d539f07",
   "metadata": {},
   "source": [
    "Sometimes you might want some more details about the actual population and its properties. You can experimeent with this using the `plot_hist_properties` method of the `Rates` class.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d501147-b5c8-469e-837a-e8f60f570455",
   "metadata": {},
   "source": [
    "## 2: SFH Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba6da3-32c4-4b74-b844-21f26a882533",
   "metadata": {},
   "source": [
    "Similar to initial conditions via the `TransientPopulations` class's `model_weights`, there are various choices of star formation histories that can be applied with the `Rates` class's `calculate_cosmic_weights`. In this section of the lab, we will explore some of these variations to see how they impact our populations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd65ee-1a79-4032-acae-f6cd58932563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sfh_variations.png', width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3481c3-4a14-46bc-9373-eb20d9959826",
   "metadata": {},
   "source": [
    "The figure above shows variations in the star formation history of the universe, either using parametric forms of the SFH based on observations (Madau+Dickinson14, Madau+Fragos17, Neijssel+19) or cosmological simulations (Nelson+18). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593c641-7627-4649-967e-a7358d55b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='met_variations.png', width=750) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677be183-4f90-4386-984a-9515b610c98d",
   "metadata": {},
   "source": [
    "The figure above shows variations in the metallicity distribution and evolution in the universe at different redshift slices. The dotted and dashed linestyles assuming a parametric metallicity evolution with log-normal dispersions of differing width, and the solid line shows the predictions from IllustrisTNG cosmological simulations. \n",
    "\n",
    "Both the star formation history and metallicity evolution constitute a major uncertainty in transient predictions from massive-star evolution, but are things that can be explored in post-processing (i.e., applied after the binaries have been simulated). Below we give parameters for various different star formation history and metallicity evolution models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba2b3d-67be-4e13-a2d8-99d294dd524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star Formation History models\n",
    "SFH_models = {\n",
    "    'IllustrisTNG' :{'SFR' : 'IllustrisTNG',\n",
    "                        'normalise':True,\n",
    "                        'Z_min':0, \n",
    "                        'Z_max':None},\n",
    "    'MadauFragos_17' : {'SFR':'Madau+Fragos17',\n",
    "                        'sigma':0.39,\n",
    "                        'normalise':True,\n",
    "                        'Z_min':0,\n",
    "                        'Z_max':None},\n",
    "    'Neijssel_19' : {'SFR':'Neijssel+19',\n",
    "                        'sigma':0.39,\n",
    "                        'normalise':True,\n",
    "                        'Z_min':0,\n",
    "                        'Z_max':None},\n",
    "    'Fujimoto24': {'SFR':'Fujimoto+24',\n",
    "                        'sigma':0.5,\n",
    "                        'normalise':True,\n",
    "                        'Z_min':0,\n",
    "                        'Z_max':None},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e37d09-9309-4a14-b302-1fa1b481d96c",
   "metadata": {},
   "source": [
    "Certain models have certain unique parameters. For example, the parametric models (e.g., `Neijssel+19`, `Madau+Fragos17`, `Fujimoto+24`) allow for one to specify the dispersion in the log-normal metallicity distribution with the `sigma` key. One can also set the minimum and maxmimum metallicity with `Z_min` and `Z_max`, respectively. The `normalise` key determines whether to renormalize the metallicity distribution so that it integrates to 1 at each redshift if `Z_min` or `Z_max` are specified. \n",
    "\n",
    "Let's compare the BBH merger rate for these differing metallicity distributions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb6d58-3721-4b14-8bfb-e206d93ca4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we calculate the intrinsic rates from each of the models\n",
    "for sfh in SFH_models.keys():\n",
    "    print(sfh)\n",
    "    BBH_merger_rates = BBH_mergers.calculate_cosmic_weights(sfh, model_weights='full_IMF', MODEL_in=SFH_models[sfh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a8d84-d4fd-4462-a03a-1fe956ef6531",
   "metadata": {},
   "source": [
    "Next, we'll plot the intrinsic rate density for merging BBHs in each of these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234a857-eb68-4f0d-8b29-a3f881e4840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for sfh in SFH_models.keys():\n",
    "    BBH_merger_rates = Rates(filename='BBH_mergers.h5', transient_name='BBH', SFH_identifier=sfh)\n",
    "    rates = BBH_merger_rates.calculate_intrinsic_rate_density()\n",
    "    ax.plot(rates.index, rates.total, label=sfh)\n",
    "\n",
    "\n",
    "ax.set_xlabel('redshift')\n",
    "ax.set_ylabel('$R$ [Gpc$^{-3}$ yr$^{-1}$]')\n",
    "ax.set_xlim(0,20)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1fae8-5bfa-4342-a77a-582b609f77d9",
   "metadata": {},
   "source": [
    "___\n",
    "## 3: Detectability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bffb4f-5e6c-4a47-a35c-c920c08d1ecb",
   "metadata": {},
   "source": [
    "So far, we've only been concerned with the _intrinsic_ rate density of transient events. However, the _detectable_ rate (how many events one would expect to detect per unit time) and _detecable_ population (intrinsic properties of the detectable population) depends on detector sensitivity. This could be, for example, a detection fraction of supernovae for a particular telescope survey, or the detection efficiency of gravitational-wave mergers by the ground-based gravitational wave detector network. These are what we call _selection effects_. \n",
    "\n",
    "Detection probability weights can be calculated for a transient population in a similar way to how transient populations are created: the `calculate_observable_population` function takes a `observable_func`, which describes the observability of a transient. \n",
    "\n",
    "Compact binaries have well-known selection effects. The figure below shows the detection probability as functions of mass, mass ratio, effective spin, and redshift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c29c5-b914-4096-8b85-26aea087eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='GW_selection_function.png', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3840038-c48e-492f-8f82-a7ff5512e86f",
   "metadata": {},
   "source": [
    "Below we'll show how to define an observable population of BBH merger based on estimated sensitivity of a design-sensitivity network of current ground-based GW detectors. This is something where we have a pre-computed grid of detection probabilities based on the system's masses, mass ratio, effective spin, and redshift. But you can create your own function in something like the `DCO_wrapper` below that uses a different selection function than the `DCO_detectability`. We'll use a projected sensitivity for the LIGO-Virgo-KAGRA network operating in O4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11983a-3600-4198-adbd-b1bed9fa067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from posydon.popsyn.transient_select_funcs import DCO_detectability\n",
    "BBH_merger_rates = Rates(filename='BBH_mergers.h5', transient_name='BBH', SFH_identifier='MadauFragos2017')\n",
    "\n",
    "def DCO_wrapper(transient_chunk, z_events_chunk, weights_chunk):\n",
    "    # once again, these can be done in chunks of the population, but we don't need to worry about it given the small population size we're using\n",
    "    sensitivity = 'O4low_H1L1V1'\n",
    "    return DCO_detectability(sensitivity, transient_chunk, z_events_chunk, weights_chunk, verbose=False)\n",
    "\n",
    "BBH_merger_rates.calculate_observable_population(DCO_wrapper, 'O4low_H1L1V1')\n",
    "\n",
    "# We can now access this observable population\n",
    "BBH_merger_rates.observable_population('O4low_H1L1V1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7da5dc-3b59-47ec-807e-cfed24681297",
   "metadata": {},
   "source": [
    "This table provides weights in units of yr$^{-1}$. If we wanted, for example, to calculate the detectable rate from the detector we specifed, we can sum up the weights for each system across all redshift columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c85f3d-03e8-41be-9cd5-2bf270a8588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_rate = BBH_merger_rates.observable_population('O4low_H1L1V1').sum().sum()\n",
    "print('Number of BBH detections predicted from O4-seneitivity detectors: {:0.2f} per year'.format(detection_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bba9b6-89b9-470f-be1f-10a378097db4",
   "metadata": {},
   "source": [
    "A little on the high end, but this is just with a default model. Varying parameters in the population ini file, the model weights, or assumptions about the star formation history, can bring this down. \n",
    "\n",
    "Selection effects are dependent on the properties of the system and where in the universe the transient event happened. For example, GW detectors are more sensitive to higher-mass systems (up to a certain point), with unequal-mass systems and systems with spins aligned opposite the orbital angular momentum having a more minor effect of decreasing the detectability. \n",
    "\n",
    "With POSYDON functionality, we can take a look at what the observable population is compared to the intrinsic population using `plot_hist_properties`. Let's look at how selection effects impact the observed distribution of BBH masses and spins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d73fb2-2a71-4c60-a38c-26e70294e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "BBH_merger_rates.plot_hist_properties('S1_mass', intrinsic=True, observable='O4low_H1L1V1', bins=np.linspace(0,60,31), normalise=True, ax=ax, label='S1', show=False)\n",
    "ax.set_ylabel('Rate density [normalised]')   # Note: we normalized this since otherwise the observable population would be so small that we wouldn't see it in the plot!\n",
    "ax.set_xlabel('Mass [Msun]')\n",
    "ax.set_xlim(0,60)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d944365-730f-4f32-a2e2-f590660a2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "BBH_merger_rates.plot_hist_properties('mass_ratio', intrinsic=True, observable='O4low_H1L1V1', bins=np.linspace(0,1,41), normalise=True, ax=ax, show=False)\n",
    "ax.set_ylabel('Rate density [normalised]')\n",
    "ax.set_xlabel('Mass ratio')\n",
    "ax.set_xlim(0,1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d964b-be66-4c7c-b275-53522927ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "BBH_merger_rates.plot_hist_properties('chi_eff', intrinsic=True, observable='O4low_H1L1V1', bins=np.linspace(-1,1,41), normalise=True, ax=ax, show=False)\n",
    "ax.set_ylabel('Rate density [normalised]')\n",
    "ax.set_xlabel('Effective Inspiral Spin')\n",
    "ax.set_xlim(-1,1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad4722-ff93-41c5-a2d9-63bb35019151",
   "metadata": {},
   "source": [
    "You can see that the observable population favors high masses, equal mass ratios, and positive effective spins compared to the underlying population. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f61c0-f9e8-491f-9362-7d07a0632322",
   "metadata": {},
   "source": [
    "## 4: Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009e9d7-00a3-4e2a-96a6-f584f79af8a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## EXERCISE\n",
    "\n",
    "So far, we've been focused on BBH mergers detected via gravitational waves. Let's try to recreate the rate density evolution and detectability of another transient: Type II supernovae. We'll be using everything learned in this lab and the previous lab to do this. \n",
    "\n",
    "1. Create a new `TransientPopulation` that targets successful core collapse (i.e., a NS is formed) of both the primary and the secondary star. We'll also want to make sure that the supernova type is a CCSN using `S1_SN_type` and `S2_SN_type` from the oneline. Note: you can create a `Population` with everything in these files since almost all go through core collapse. \n",
    "2. Calculate model weights for this transient population assuming the `full_IMF` that uses a Kroupa IMF from the previous lab. \n",
    "3. Plot the intrinsic rate density of Type II supernovae assuming a star formation history and metallicity evolution from the IllustrisTNG simulations.\n",
    "4. **Hard**: Assume some simple and artificial selection function that is dependent on the luminosity distance of the SN (that scales as $(d_L / 1 Mpc)^{-2}$ and the mass of the progenitor (that scales as $(M / M_\\odot)^{3}$. Note that you'll have to use astropy's `cosmo.luminosity_distance(z)` function to get luminosity distances from redshifts, and it's helpful to create an interpolant for this ahead of time to speed things up with scipy's `interp1d`. The detectability function takes in a transient population, z_events, and weights and returns a 2D array of new weights (the original weights times a detection probability, which ranges from 0 to 1). \n",
    "5. Plot the intrinsic and detectable mass distribution of the SN progenitors assuming these selection effects. \n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f92bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed4fff6-66bc-4e7d-b98f-deda176b9012",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "\n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "    \n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from posydon.popsyn.synthetic_population import Population\n",
    "from posydon.popsyn.synthetic_population import TransientPopulation\n",
    "from posydon.popsyn.synthetic_population import Rates\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "\n",
    "# read in population files\n",
    "print(\"Reading in population files...\")\n",
    "pop_files = ['1e-04_Zsun_population.h5',\n",
    "             '1e-03_Zsun_population.h5',\n",
    "             '1e-02_Zsun_population.h5',\n",
    "             '1e-01_Zsun_population.h5',\n",
    "             '2e-01_Zsun_population.h5',\n",
    "             '4.5e-01_Zsun_population.h5',\n",
    "             '1e+00_Zsun_population.h5',\n",
    "             '2e+00_Zsun_population.h5']   \n",
    "\n",
    "for file in pop_files:\n",
    "    pop = Population(file)\n",
    "\n",
    "    # let's also determine the formation channels for each system so we have them for later\n",
    "    pop.calculate_formation_channels(mt_history=True)\n",
    "\n",
    "    # export all systems, we'll parse the CCSN info when we create the transient population\n",
    "    pop.export_selection(pop.indices, 'CoreCollapse.h5', append=True)\n",
    "\n",
    "\n",
    "\n",
    "# create transient population\n",
    "print(\"\\n\\n\\nCreating transient population...\")\n",
    "\n",
    "CC_pop = Population('CoreCollapse.h5')\n",
    "def CCSN_selection_function(history_chunk, oneline_chunk, formation_channel_chunk):\n",
    "    '''Select succesfull CCSN events (NS formation) and return their time and metallicity.\n",
    "\n",
    "    This function is used for transient population creation.\n",
    "    '''\n",
    "\n",
    "    # primary star\n",
    "    S1CC_mask = oneline_chunk['S1_SN_type'] == 'CCSN'\n",
    "\n",
    "    S1CC_hist = history_chunk.loc[oneline_chunk[S1CC_mask].index.tolist()]\n",
    "    S1CC = S1CC_hist[(S1CC_hist['event'] == 'CC1').shift(1, fill_value=False)]\n",
    "    successfull = S1CC[S1CC['S1_state'] == 'NS']\n",
    "\n",
    "    CC1_dataframe = pd.DataFrame()\n",
    "    CC1_dataframe['time'] = successfull['time'] / 1e6\n",
    "    CC1_dataframe['metallicity'] = oneline_chunk.loc[successfull.index.tolist()]['metallicity']\n",
    "    CC1_dataframe['mass'] = oneline_chunk.loc[successfull.index.tolist()]['S1_mass_i']\n",
    "\n",
    "\n",
    "    # secondary star\n",
    "    S2CC_mask = oneline_chunk['S2_SN_type'] == 'CCSN'\n",
    "    S2CC_hist = history_chunk.loc[oneline_chunk[S2CC_mask].index.tolist()]\n",
    "    S2CC = S2CC_hist[(S2CC_hist['event'] == 'CC2').shift(1, fill_value=False)]\n",
    "    successfull = S2CC[S2CC['S2_state'] == 'NS']\n",
    "\n",
    "    CC2_dataframe = pd.DataFrame()\n",
    "    CC2_dataframe['time'] = successfull['time'] / 1e6\n",
    "    CC2_dataframe['metallicity'] = oneline_chunk.loc[successfull.index.tolist()]['metallicity']\n",
    "    CC2_dataframe['mass'] = oneline_chunk.loc[successfull.index.tolist()]['S2_mass_i']\n",
    "\n",
    "    out_dataframe = pd.concat([CC1_dataframe, CC2_dataframe])\n",
    "\n",
    "    return out_dataframe\n",
    "    \n",
    "CCSN = CC_pop.create_transient_population(CCSN_selection_function, 'CCSN')\n",
    "\n",
    "\n",
    "\n",
    "# calculate model weights\n",
    "print(\"\\n\\n\\nCalculating model weights...\")\n",
    "\n",
    "full_IMF = {'number_of_binaries': 10000,\n",
    " 'binary_fraction_scheme': 'const',\n",
    " 'binary_fraction_const': 0.7,\n",
    " 'star_formation': 'burst',\n",
    " 'max_simulation_time': 13800000000.0,\n",
    " 'primary_mass_scheme': 'Kroupa2001',\n",
    " 'primary_mass_min': 0.01,\n",
    " 'primary_mass_max': 200.0,\n",
    " 'secondary_mass_scheme': 'flat_mass_ratio',\n",
    " 'secondary_mass_min': 0.01*0.05,\n",
    " 'secondary_mass_max': 200.0,\n",
    " 'q_min':0,\n",
    " 'q_max':1,\n",
    " 'orbital_scheme': 'period',\n",
    " 'orbital_period_scheme': 'Sana+12_period_extended',\n",
    " 'orbital_period_min': 0.5,\n",
    " 'orbital_period_max': 6000.0,\n",
    " 'eccentricity_scheme': 'zero'}\n",
    "\n",
    "_ = CCSN.calculate_model_weights('full_IMF', population_parameters=full_IMF)\n",
    "\n",
    "\n",
    "\n",
    "# calculate rates\n",
    "print(\"\\n\\n\\nCalculating rates (this takes a little bit of time)...\")\n",
    "SFH_model = {'SFR' : 'IllustrisTNG',\n",
    "             'normalise':True,\n",
    "             'Z_min':0, \n",
    "             'Z_max':None}\n",
    "\n",
    "CCSN_rates = CCSN.calculate_cosmic_weights('IllustrisTNG', model_weights='full_IMF', MODEL_in=SFH_model)   # this takes a little bit since there are so many systems\n",
    "\n",
    "\n",
    "\n",
    "# plot merger rate density evolution\n",
    "print(\"Plotting merger rate density evolution...\")\n",
    "CCSN_rates = Rates(filename='CoreCollapse.h5', transient_name='CCSN', SFH_identifier='IllustrisTNG')\n",
    "CCSN_rates.calculate_intrinsic_rate_density()\n",
    "\n",
    "CCSN_rates.plot_intrinsic_rate(channels=False, xlim=(0,13))\n",
    "\n",
    "\n",
    "\n",
    "# calculate detectability\n",
    "print(\"\\n\\n\\nCalculating detectability...\")\n",
    "\n",
    "CCSN_rates = Rates(filename='CoreCollapse.h5', transient_name='CCSN', SFH_identifier='IllustrisTNG')\n",
    "def ccsn_det(transient_pop_chunk, z_events_chunk, weights_chunk):\n",
    "\n",
    "    z_grid = np.linspace(0,50,1000)\n",
    "    dL_grid = cosmo.luminosity_distance(z_grid)\n",
    "    z_to_dL_interp = interp1d(z_grid, dL_grid)   # Mpc\n",
    "\n",
    "    dL = z_to_dL_interp(z_events_chunk)\n",
    "    masses = np.ones_like(z_events_chunk) * np.atleast_2d(transient_pop_chunk['mass']).T\n",
    "\n",
    "    pdet_weights = (dL/1.0)**(-2) * masses**(3.)\n",
    "    always_detectable_mask = pdet_weights>1\n",
    "    pdet_weights[always_detectable_mask] = 1.0\n",
    "\n",
    "    return pdet_weights * weights_chunk\n",
    "\n",
    "CCSN_rates.calculate_observable_population(ccsn_det, 'fake_telescope')\n",
    "\n",
    "# We can now access this observable population\n",
    "CCSN_rates.observable_population('fake_telescope')\n",
    "\n",
    "detection_rate = CCSN_rates.observable_population('fake_telescope').sum().sum()\n",
    "print('Number of CCSN detected by our fake telescope: {:0.2f} per year'.format(detection_rate))\n",
    "\n",
    "\n",
    "\n",
    "# plot intrinsic versus observed pop\n",
    "print(\"\\n\\n\\nPlotting intrinsic versus observed population masses...\")\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "CCSN_rates.plot_hist_properties('mass', intrinsic=True, observable='fake_telescope', bins=np.linspace(0,60,31), normalise=True, ax=ax, show=False)\n",
    "ax.set_ylabel('Rate density [normalised]')   # Note: we normalized this since otherwise the observable population would be so small that we wouldn't see it in the plot!\n",
    "ax.set_xlabel('Mass [Msun]')\n",
    "ax.set_xlim(0,60)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posydon-conda",
   "language": "python",
   "name": "posydon-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
