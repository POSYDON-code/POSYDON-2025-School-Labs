{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b7a050",
   "metadata": {},
   "source": [
    "# Simulating the X-ray luminosity function (XLF) of an X-ray binary (XRB) population\n",
    "\n",
    "In the previous labs, you explored populations of double compact object mergers, supernovae, and gamma-ray bursts. These phenomena are instantaneous transient events: they occur on timescales much shorter than the typical lifetime of a binary system. Within the POSYDON framework, such events can be modeled efficiently using an initialâ€“final interpolation scheme, which maps the initial binary properties directly to their final, post-event outcome.\n",
    "\n",
    "X-ray binaries, however, are fundamentally different. They represent evolutionary phases of binary systems that persist for a non-negligible fraction of the systemâ€™s lifetime. During these phases, the properties of the binariesâ€”such as component masses, orbital periods, and X-ray luminositiesâ€”evolve continuously with time. Because of this temporal evolution, an initialâ€“final interpolation approach is not sufficient to capture their behavior.\n",
    "\n",
    "### Modeling strategies for X-ray binary populations\n",
    "\n",
    "There are two principal approaches to model populations of systems like X-ray binaries:\n",
    "1.  Snapshot method\n",
    "-   Evolve each binary up to a pre-specified age.\n",
    "-   Record its properties at that moment.\n",
    "-   If the binary is in an X-ray phase at that time, include it in the population statistics.\n",
    "2.  Full evolutionary history method (Lab2)\n",
    "-   Evolve each binary from zero-age to the end of its life.\n",
    "-   Identify all intervals during which the system qualifies as an X-ray binary.\n",
    "-   Record the evolving properties of the system across these intervals, weighting them by the time spent in each state.\n",
    "\n",
    "The \"snapshot\" method is conceptually straightforward but computationally inefficient: a binary may have been an X-ray source at earlier or later times, and its observable properties evolve during the X-ray phase, which is not fully captured by a single snapshot. This \"full evolutionary history\" method is more computationally efficient and captures the temporal evolution of the population in greater detail. It is however conceptualy more complex to implement.\n",
    "\n",
    "![XRB schematic](xrb_schematic.png)\n",
    "<details>\n",
    "<summary>Code to produce this diagram</summary>\n",
    "\n",
    "~~~python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 3))\n",
    "\n",
    "# Timeline\n",
    "ax.hlines(1, 0, 11, color=\"black\")\n",
    "ax.set_ylim(0.5, 1.6)\n",
    "ax.set_xlim(0, 11)\n",
    "\n",
    "# Key events\n",
    "events = [0, 2, 8, 10]\n",
    "labels = [\"ZAMS\", \"1st Supernova\", \"2nd Supernova\", \"DCO formation\"]\n",
    "colors = [\"black\", \"red\", \"red\", \"orange\"]\n",
    "\n",
    "for x, label, c in zip(events, labels, colors):\n",
    "    ax.plot(x, 1, \"o\", color=c)\n",
    "    ax.text(x, 1.12, label, ha=\"center\", color=c, fontsize=10)\n",
    "\n",
    "# X-ray binary phase between the two SNe\n",
    "ax.hlines(0.9, 3, 7, color=\"blue\", linewidth=6, alpha=0.3)\n",
    "ax.text(5, 0.72, \"X-ray Binary Phase\", ha=\"center\", color=\"blue\")\n",
    "\n",
    "# Snapshot method arrow (single age cut)\n",
    "ax.annotate(\"Snapshot method\\n(one age)\", xy=(6, 1.05), xytext=(6, 1.38),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"darkgreen\"),\n",
    "            ha=\"center\", color=\"darkgreen\", fontsize=9)\n",
    "\n",
    "# Full history method bracket\n",
    "ax.annotate(\"\", xy=(3, 1.28), xytext=(7, 1.28),\n",
    "            arrowprops=dict(arrowstyle=\"|-|\", color=\"purple\", linewidth=2))\n",
    "ax.text(5, 1.35, \"Full history method\", ha=\"center\", color=\"purple\", fontsize=9)\n",
    "\n",
    "# Formatting\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"From ZAMS to Double Compact Object Formation\", fontsize=14)\n",
    "\n",
    "plt.savefig(\"xrb_schematic.png\", dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "~~~\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "In this first lab, we will adopt the snapshot method: evolving binaries to a fixed age and recording their properties if they are X-ray binaries at that time. This will introduce the concepts and workflow for simulating X-ray binary populations. In the following lab, we will implement the full evolutionary history method, which provides a more complete and efficient treatment of these systems.\n",
    "\n",
    "\n",
    "\n",
    "**By the end of this exercise, you should be able to:**\n",
    "-   Set up and run a POSYDON population synthesis calculation appropriate for the modelling of high-mass X-ray binaries.\n",
    "-   Load and inspect simulated populations, extracting key information such as the number of systems, simulated stellar mass, and their formation pathways.\n",
    "-   Identify and select X-ray binaries within the broader population at a fixed age, using criteria based on stellar states and accretion properties.\n",
    "-   Compute and analyze the X-ray luminosity function (XLF) by combining the luminosities of the simulated XRBs into a population distribution.\n",
    "-   Visualize and interpret the results, linking simulation outputs to astrophysical observables, and discussing how population synthesis can be used to test models of binary evolution against X-ray observations of galaxies.\n",
    "\n",
    "\n",
    "\n",
    "## 1.   Setting up the population run\n",
    "\n",
    "First, let's load some required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import posydon\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"text.usetex\"] = False\n",
    "mpl.rcParams[\"font.family\"] = \"DejaVu Serif\"\n",
    "\n",
    "from posydon.config import PATH_TO_POSYDON, PATH_TO_POSYDON_DATA\n",
    "\n",
    "# importing path to our lab data\n",
    "data_path = os.path.join(os.path.dirname(PATH_TO_POSYDON_DATA), \"2025_school_data/populations/XRB_10_pops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4032327",
   "metadata": {},
   "source": [
    "then, copy default population parameters file to current directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_params = os.path.join(PATH_TO_POSYDON, \"posydon/popsyn/population_params_default.ini\")\n",
    "shutil.copyfile(path_to_params, './population_params.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869e4d1",
   "metadata": {},
   "source": [
    "We need to open the population_params.ini file that we just copied and edit it to adjust the parameters we need for our simulations. As in the previous lab, we will explore high-mass X-ray binaries, in start-forming galaxies. Often, star-formation rates in galaxies are measured assuming a constant star-foramtion rate over the last 100Myr. This is excactly what we will assume hear as well. What are the changes that we would need to make in population_params.ini file?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal code</summary>\n",
    "\n",
    "~~~python\n",
    "star_formation = 'constant'\n",
    "# 'constant', 'burst', 'custom_linear', 'custom_log10',\n",
    "# 'custom_linear_histogram', 'custom_log10_histogram'\n",
    "max_simulation_time = 1e8\n",
    "# float (0, inf)\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206abc0f",
   "metadata": {},
   "source": [
    "Let's also define that we want to run 100 binaries at two different metallicities, Solar and 10% Solar.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal code</summary>\n",
    "\n",
    "~~~python\n",
    "  number_of_binaries = 100\n",
    "    # int (0, inf)\n",
    "  metallicity = [1., 0.1]\n",
    "    # in units of solar metallicity: list of float\n",
    "    # e.g. [2., 1., 0.45, 0.2, 0.1, 0.01, 0.001, 0.0001]\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06737d1f",
   "metadata": {},
   "source": [
    "Now it is time to run our test population. We will use as before the `PopulationRunner` class to set up the run, by reading the parameters from the file we just copied and edited to our current directory, and then run it with the `evolve` method. This might take a few minutes...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from posydon.popsyn.synthetic_population import PopulationRunner\n",
    "poprun = PopulationRunner('./population_params.ini', verbose=True)\n",
    "poprun.evolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b80de1",
   "metadata": {},
   "source": [
    "We now need to load back the file of the population we run. Let's load the Solar metalicity population using the `Population` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from posydon.popsyn.synthetic_population import Population\n",
    "\n",
    "pop_path = os.path.join(data_path, '1e+00_Zsun_population.h5')\n",
    "pop = Population(pop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef11ce",
   "metadata": {},
   "source": [
    "There, we can check for things like the simulated mass, the number of systems, or look in a bit more detail as specific binary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pop.mass_per_metallicity)\n",
    "# you can also access the total number of systems in the file with\n",
    "print(pop.number_of_systems)\n",
    "# select only binary_index 5\n",
    "print(pop.history[5])\n",
    "# check the history lengths of binaries\n",
    "print(pop.history_lengths)\n",
    "# Calculate and inspect the different formation channels\n",
    "pop.calculate_formation_channels(mt_history=True)\n",
    "# the formation channels are loaded in with pop.formation_channels\n",
    "pop.formation_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa4c28",
   "metadata": {},
   "source": [
    "Unfortunately, with a 10 binary population, we cannot do much. To get a better feeling of what the population synthesis can do, we will use a pre-calculated population with 100,000 binaries at Z=0.0142 (solar metallicity). The file is called `1e+00_Zsun_population.h5` and it is located in the `data` folder of posydon. You can load it directly from there using the `Population` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.dirname(PATH_TO_POSYDON_DATA), \"2025_school_data/populations/XRB_100K_pops\")\n",
    "pop_path = os.path.join(data_path, '1e+00_Zsun_population.h5')\n",
    "\n",
    "pop = Population(pop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1deb1",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "### Excercise 1\n",
    "Check the total number of binaries in this population, the simulated mass, how many unique formation pathways the binaries of this population have followed, and how many binaries have gone through each channel. \n",
    "\n",
    "Since in this lab, we only care about the properties of the binary at the end of our simulations, i.e. at 100Myr, we do not need to deal in most cases with the `history` but we can look at the `oneline` instead, which contains the initial and final properties of the binary. Thus, it would be handy to print a list of all the `keys` of `oneline`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c611ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write here your code for Excercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71640c28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "print(\"The simulated mass  and numbe of binaries per metallicity is:\")\n",
    "print(pop.mass_per_metallicity)\n",
    "print('')\n",
    "\n",
    "# Calculate and inspect the different formation channels\n",
    "pop.calculate_formation_channels(mt_history=True)\n",
    "print('')\n",
    "\n",
    "# the formation channels are loaded in with pop.formation_channels.\n",
    "print(\"The number of binaries following each formation channels are:\")\n",
    "print(pop.formation_channels.value_counts())\n",
    "print('')\n",
    "\n",
    "#The keys of oneline are:\n",
    "print(\", \".join(list(pop.oneline[0].keys())))\n",
    "print('')\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d40b84",
   "metadata": {},
   "source": [
    "## 2.   Selecting the XRB population\n",
    "\n",
    "Out of the entire population that we simulated, only a small fraction are potentially XRBs. So we do not need to be carrying everything around. To do that, we are gonna try to follow as closely as possible the tutorial on [\"Transient populations\"](https://posydon.org/POSYDON/latest/tutorials-examples/population-synthesis/bbh_analysis.html). You can consult that for inspiration. However, Since here we are dealing with XRBs and not transients, some of the steps will have to be adapted.\n",
    "\n",
    "<div class='alert alert-success'>\n",
    "    \n",
    "### Excercise 2\n",
    "First, let's filter our populations to only select potential XRBs. For a binary to be an XRB, one of the two components must be a neutron star or a black hole, while the other must be a normal, non-compact star. Of course, some binaries get disrupted during the supernova. We need to get rid of those as well. The goal to save the indices of all binaries that may be XRBs into a list that we will name `selected_indices`.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Hint (click to reveal):</summary></b>\n",
    "\n",
    "From the states of compact object companions, apart from `NS` and `BH`  we also want to exclude the states `WD` and `massless remnant`.\n",
    "\n",
    "Following the tutorial logic, we need to create a temporary dataframe from the `oneline` that includes the fields `S1_state_f`,  `S1_state_f`, and `state_f`. That way, it will be easier to buid a mask that implements our logic. \n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code for Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c829fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "tmp_data = pop.oneline.select(columns=['S1_state_f', 'S2_state_f'])\n",
    "S1_state = tmp_data['S1_state_f']\n",
    "S2_state = tmp_data['S2_state_f']\n",
    "\n",
    "# get the indices of all systems\n",
    "indices = tmp_data.index\n",
    "\n",
    "compact = {'BH', 'NS'}\n",
    "exclude = {'BH', 'NS', 'massless_remnant', 'WD'}\n",
    "\n",
    "mask = (S1_state.isin(compact) & ~S2_state.isin(exclude)) | (S2_state.isin(compact) & ~S1_state.isin(exclude))\n",
    "\n",
    "# get the indices that satisfy all the conditions\n",
    "selected_indices = indices[mask].to_list()\n",
    "\n",
    "print(selected_indices)\n",
    "pop.oneline[selected_indices]\n",
    "\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b6ac3",
   "metadata": {},
   "source": [
    "Before we continue, let's save this filtered population into a new file (e.g. `XRBs.h5`), and then reload it into a new population that we will call `XRB_pop`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42425621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set overwrite to False to add to the file\n",
    "pop.export_selection(selected_indices, 'XRBs.h5', append=False, overwrite=True)\n",
    "\n",
    "XRB_pop = Population('XRBs.h5')\n",
    "print(XRB_pop.number_of_systems)\n",
    "\n",
    "#Note that the simulated mass is the same as what was reported before the filtering. This information is retained.\n",
    "print(XRB_pop.mass_per_metallicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4486b1",
   "metadata": {},
   "source": [
    "The next step in the [\"Transient populations\"](https://posydon.org/POSYDON/latest/tutorials-examples/population-synthesis/bbh_analysis.html) tutorial is to build a selection function. There, we basically need to constract a pandas dataframe which contains only the information that we need for our further analysis. We will build this step by step, as in the tutorial.\n",
    "\n",
    "For the later calculations we are gonna do, it is convenient to switch from an S1 / S2 notation to donnor / accretor notation. To do that, we will need in the selection funtion to loop over the systems and check which one is the compact object (BH or NS) and assign that to be the accretor, while the other star will be the donor. In contrast to the the tutorial for \"transients\" where we want to be searching the history, here we only care about the final state, so the oneline is sufficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6138210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XRB_selection_function(history_chunk, oneline_chunk, formation_channels_chunk=None):\n",
    "    '''A XRB selection function to create a population of XRBs, where we store only the necessary information.'''\n",
    "\n",
    "    indices = oneline_chunk.index.to_numpy()\n",
    "    df_XRBs = pd.DataFrame(index = indices)\n",
    "\n",
    "\n",
    "    df_XRBs['time'] = oneline_chunk['time_f'] * 1e-6 #Myr\n",
    "    df_XRBs['metallicity'] = oneline_chunk['metallicity'] #This is not really necessary in our case, since we have one file per metallicity, but it is required by the fanctionality of the \"transient population we will use\"\n",
    "\n",
    "  \n",
    "    # Compact object types\n",
    "    compact_types = {'BH', 'NS'}\n",
    "\n",
    "    # Prepare new columns\n",
    "    donor_mass = []\n",
    "    accretor_mass = []\n",
    "    donor_type = []\n",
    "    accretor_type = []\n",
    "\n",
    "\n",
    "    # Loop over each system\n",
    "    for s1, s2, m1, m2 in zip(oneline_chunk['S1_state_f'], oneline_chunk['S2_state_f'], oneline_chunk['S1_mass_f'], oneline_chunk['S2_mass_f']):\n",
    "        if s1 in compact_types and s2 not in compact_types:\n",
    "            accretor_mass.append(m1)\n",
    "            accretor_type.append(s1)\n",
    "            donor_mass.append(m2)\n",
    "            donor_type.append(s2)\n",
    "\n",
    "        elif s2 in compact_types and s1 not in compact_types:\n",
    "            accretor_mass.append(m2)\n",
    "            accretor_type.append(s2)\n",
    "            donor_mass.append(m1)\n",
    "            donor_type.append(s1)\n",
    "\n",
    "        else:\n",
    "            # If neither or both are compact, fill with NaN or original values\n",
    "            accretor_mass.append(float('nan'))\n",
    "            accretor_type.append(None)\n",
    "            donor_mass.append(float('nan'))\n",
    "            donor_type.append(None)\n",
    "\n",
    "    # Add new columns to DataFrame\n",
    "    df_XRBs['donor_mass'] = donor_mass\n",
    "    df_XRBs['accretor_mass'] = accretor_mass\n",
    "    df_XRBs['donor_type'] = donor_type\n",
    "    df_XRBs['accretor_type'] = accretor_type\n",
    "\n",
    "    return df_XRBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f788bd5",
   "metadata": {},
   "source": [
    "Let's test our function to one binary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XRB_selection_function(XRB_pop.history[0], XRB_pop.oneline[0], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dc52d",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "### Excercise 3\n",
    "\n",
    "Now let's modify `XRB_selection_function` that we built above, to also include additional information, such as donor and accretor radii, mass loss/transfer rates, orbital period, and eccentricity, as well as the rotational frequency of the donor and the spin of the accreting compact object.\n",
    "\n",
    "</div>   \n",
    " \n",
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Hint (click to reveal):</summary></b>\n",
    "\n",
    "In POSYDON, we keep track of the mass loss/gain rate of each component, as well the mass transfer rate between the two components. The latter is non-zero only for Roche lobe overfilling systems. Let'. save all three quantities, i.e.: `S1_lg_mdot_f`, `S2_lg_mdot_f`, and `lg_mtransfer_rate_f`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here your code for Excercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e5cc7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "import pandas as pd\n",
    "def XRB_selection_function(history_chunk, oneline_chunk, formation_channels_chunk=None):\n",
    "    '''A XRB selection function to create a population of XRBs, where we store only the necessary information.'''\n",
    "\n",
    "    indices = oneline_chunk.index.to_numpy()\n",
    "    df_XRBs = pd.DataFrame(index = indices)\n",
    "\n",
    "    #in contrast to the the tutorial for \"transient\" where we want to be searching the history, here we only care about the final state, so the oneline is sufficient.\n",
    "\n",
    "    df_XRBs['time'] = oneline_chunk['time_f'] * 1e-6 #Myr\n",
    "    df_XRBs['time_of_birth'] = oneline_chunk['time_i'] * 1e-6 #Myr\n",
    "    df_XRBs['metallicity'] = oneline_chunk['metallicity'] #This is not really necessary in our case, since we have one file per metallicity, but it is required by the fanctionality of the \"transient population we will use\"\n",
    "\n",
    "    # For the later calculations we are gonna do, it is convenient to switch from an S1 / S2 notation to donnor / accretor notation. \n",
    "    # To do that, we will loop over the systems and check which one is the compact object (BH or NS) and assign that to be the accretor, while the other star will be the donor.\n",
    "    # We will also store the type of compact object in a separate column.\n",
    "  \n",
    "    # Compact object types\n",
    "    compact_types = {'BH', 'NS'}\n",
    "\n",
    "    # Prepare new columns\n",
    "    donor_mass = []\n",
    "    accretor_mass = []\n",
    "    donor_state = []\n",
    "    accretor_state = []\n",
    "    donor_log_R = []\n",
    "    accretor_log_R = []\n",
    "    donor_lg_mdot = [] \n",
    "    accretor_lg_mdot = []\n",
    "    donor_surf_avg_omega_div_omega_crit = []\n",
    "    accretor_spin = []\n",
    "\n",
    "\n",
    "\n",
    "    # Loop over each system\n",
    "    for s1, s2, m1, m2, logr1, logr2, mdot1, mdot2, omega1, omega2, spin1, spin2 in zip(oneline_chunk['S1_state_f'], oneline_chunk['S2_state_f'], oneline_chunk['S1_mass_f'], oneline_chunk['S2_mass_f'], oneline_chunk['S1_log_R_f'], oneline_chunk['S2_log_R_f'], oneline_chunk['S1_lg_mdot_f'], oneline_chunk['S2_lg_mdot_f'], oneline_chunk['S1_surf_avg_omega_div_omega_crit_f'], oneline_chunk['S2_surf_avg_omega_div_omega_crit_f'], oneline_chunk['S1_spin_f'], oneline_chunk['S2_spin_f']):\n",
    "        if s1 in compact_types and s2 not in compact_types:\n",
    "            accretor_mass.append(m1)\n",
    "            accretor_state.append(s1)\n",
    "            accretor_log_R.append(logr1)\n",
    "            accretor_lg_mdot.append(mdot1)\n",
    "            accretor_spin.append(spin1)\n",
    "            donor_mass.append(m2)\n",
    "            donor_state.append(s2)\n",
    "            donor_log_R.append(logr2)   \n",
    "            donor_lg_mdot.append(mdot2)\n",
    "            donor_surf_avg_omega_div_omega_crit.append(omega2)\n",
    "        elif s2 in compact_types and s1 not in compact_types:\n",
    "            accretor_mass.append(m2)\n",
    "            accretor_state.append(s2)\n",
    "            accretor_log_R.append(logr2)\n",
    "            accretor_lg_mdot.append(mdot2)\n",
    "            accretor_spin.append(spin2)\n",
    "            donor_mass.append(m1)\n",
    "            donor_state.append(s1)\n",
    "            donor_log_R.append(logr1)\n",
    "            donor_lg_mdot.append(mdot1)\n",
    "            donor_surf_avg_omega_div_omega_crit.append(omega1)\n",
    "        else:\n",
    "            # If neither or both are compact, fill with NaN or original values\n",
    "            accretor_mass.append(float('nan'))\n",
    "            accretor_state.append(None)\n",
    "            accretor_log_R.append(float('nan'))\n",
    "            accretor_lg_mdot.append(float('nan'))\n",
    "            accretor_spin.append(float('nan'))\n",
    "            donor_mass.append(float('nan'))\n",
    "            donor_state.append(None)\n",
    "            donor_log_R.append(float('nan'))\n",
    "            donor_lg_mdot.append(float('nan'))\n",
    "            donor_surf_avg_omega_div_omega_crit.append(float('nan'))\n",
    "\n",
    "    # Add new columns to DataFrame\n",
    "    df_XRBs['donor_mass'] = donor_mass\n",
    "    df_XRBs['accretor_mass'] = accretor_mass\n",
    "    df_XRBs['donor_state'] = donor_state\n",
    "    df_XRBs['accretor_state'] = accretor_state\n",
    "    df_XRBs['donor_log_R'] = donor_log_R\n",
    "    df_XRBs['accretor_log_R'] = accretor_log_R\n",
    "    df_XRBs['donor_lg_mdot'] = donor_lg_mdot\n",
    "    df_XRBs['accretor_lg_mdot'] = accretor_lg_mdot\n",
    "    df_XRBs['donor_surf_avg_omega_div_omega_crit'] = donor_surf_avg_omega_div_omega_crit\n",
    "    df_XRBs['accretor_spin'] = accretor_spin\n",
    "\n",
    "    # Finaly, add columns that are not associated to teh donor or the accretor\n",
    "    df_XRBs['orbital_period'] = oneline_chunk['orbital_period_f'].to_numpy()  # days\n",
    "    df_XRBs['eccentricity'] = oneline_chunk['eccentricity_f'] \n",
    "    df_XRBs['lg_mtransfer_rate'] = oneline_chunk['lg_mtransfer_rate_f'] #Msun/yr\n",
    "\n",
    "\n",
    "    return df_XRBs\n",
    "\n",
    "~~~\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee388d54",
   "metadata": {},
   "source": [
    "We just have one more quantity to calculate, bu it is an important one: the X-ray luminosity! Let's try to follow a simplified of the approach describe in Section 2.2. of [Misra et al. (2023)](https://ui.adsabs.harvard.edu/abs/2023A%26A...672A..99M/abstract), where we will neglect for now Be XRBs, as well as geometrical beaming effects of compact objects accreting at super-Eddington rates.\n",
    "\n",
    "Let's write a function that takes as arguments the masses, radii, and types of the donor and the accretor, as well as the mass transfer rate between the donor and the accretor and the mass-loss rate of the donor star. The latter includes both wind mass loss and mass transfer due to RLO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440afec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (cgs)\n",
    "G = 6.67430e-8\n",
    "Msun = 1.98847e33\n",
    "Rsun = 6.957e10\n",
    "c = 2.99792458e10\n",
    "year = 3.15576e7\n",
    "\n",
    "def bh_efficiency_from_spin(a):\n",
    "    if a is None or not np.isfinite(a):\n",
    "        return 0.1\n",
    "    a = float(np.clip(a, 0.0, 0.998))\n",
    "    return 0.057 + 0.38 * a  # crude approx\n",
    "\n",
    "def separation_from_period(P_days, Mtot_Msun):\n",
    "    P = float(P_days) * 86400.0\n",
    "    Mtot = float(Mtot_Msun) * Msun\n",
    "    return (G * Mtot * (P / (2.0 * np.pi))**2)**(1.0/3.0)  # cm\n",
    "\n",
    "def guess_wind_speed(donor_mass_Msun, donor_radius_Rsun, scale=2.6):\n",
    "    M = float(donor_mass_Msun) * Msun\n",
    "    R = float(donor_radius_Rsun) * Rsun\n",
    "    v_esc = np.sqrt(2 * G * M / max(R, 1e-10))\n",
    "    return scale * v_esc  # cm/s\n",
    "\n",
    "def bhl_mdot_acc(M_acc_Msun, Mdot_w_Msun_per_yr, a_cm, v_rel_cms, alpha_BHL=1.0):\n",
    "    Macc = float(M_acc_Msun) * Msun\n",
    "    Mdot_w = float(max(Mdot_w_Msun_per_yr, 0.0)) * Msun / year  # g/s\n",
    "    vrel4 = max(v_rel_cms, 1.0)**4\n",
    "    a2 = max(a_cm, 1.0)**2\n",
    "    frac = alpha_BHL * (G**2 * Macc**2) / (a2 * vrel4)\n",
    "    return frac * Mdot_w  # g/s\n",
    "\n",
    "def _lg_msunyr_to_msunyr(lg_rate):\n",
    "    if lg_rate is None or not np.isfinite(lg_rate):\n",
    "        return 0.0\n",
    "    return 10.0**float(lg_rate)\n",
    "\n",
    "def compute_Lx_components(\n",
    "    donor_mass, donor_log_R,\n",
    "    accretor_mass, accretor_type,\n",
    "    lg_mtransfer_rate, donor_lg_mdot, accretor_lg_mdot,\n",
    "    orbital_period_days=None, accretor_spin=None):\n",
    "\n",
    "    # Efficiency\n",
    "    if accretor_type == 'NS':\n",
    "        eta = 0.2\n",
    "    elif accretor_type == 'BH':\n",
    "        eta = bh_efficiency_from_spin(accretor_spin)\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan  # non-compact accretor\n",
    "\n",
    "    # Rates in Msun/yr\n",
    "    mdot_rlo_Msunyr = _lg_msunyr_to_msunyr(accretor_lg_mdot)          # RLO only\n",
    "    mdot_wind_only_Msunyr = _lg_msunyr_to_msunyr(donor_lg_mdot) - _lg_msunyr_to_msunyr(lg_mtransfer_rate)\n",
    "\n",
    " \n",
    "    # mdot_rlo_Msunyr = _lg_msunyr_to_msunyr(lg_mtransfer_rate)          # RLO only\n",
    "    # mdot_donor_total_Msunyr = _lg_msunyr_to_msunyr(donor_lg_mdot)       # winds + possible RLO\n",
    "    # mdot_wind_only_Msunyr = max(mdot_donor_total_Msunyr - mdot_rlo_Msunyr, 0.0)\n",
    "\n",
    "    # RLO luminosity (no Edd cap)\n",
    "    mdot_rlo_gps = mdot_rlo_Msunyr * Msun / year\n",
    "    Lx_RLO = eta * mdot_rlo_gps * c**2 if mdot_rlo_Msunyr > 0.0 else 0.0\n",
    "\n",
    "    # BHL luminosity (no Edd cap). If info missing, set to 0.\n",
    "    Lx_BHL = 0.0\n",
    "\n",
    "    a = separation_from_period(orbital_period_days, (donor_mass or 0.0) + (accretor_mass or 0.0))\n",
    "    donor_Rsun = 10.0**donor_log_R\n",
    "    v_w = guess_wind_speed(donor_mass, donor_Rsun)\n",
    "    v_orb = 2.0 * np.pi * a / (float(orbital_period_days) * 86400.0)\n",
    "    v_rel = np.sqrt(v_w**2 + v_orb**2)  # ignore eccentricity\n",
    "    mdot_bhl_gps = bhl_mdot_acc(accretor_mass, mdot_wind_only_Msunyr, a, v_rel)\n",
    "    if np.isfinite(mdot_bhl_gps) and mdot_bhl_gps > 0.0:\n",
    "        Lx_BHL = eta * mdot_bhl_gps * c**2\n",
    "\n",
    "    Lx_total = Lx_RLO + Lx_BHL\n",
    "    return float(Lx_RLO), float(Lx_BHL), float(Lx_total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def XRB_selection_function(history_chunk, oneline_chunk, formation_channels_chunk=None):\n",
    "    '''A XRB selection function to create a population of XRBs, where we store only the necessary information.'''\n",
    "\n",
    "    indices = oneline_chunk.index.to_numpy()\n",
    "    df_XRBs = pd.DataFrame(index = indices)\n",
    "\n",
    "    #in contrast to the the tutorial for \"transient\" where we want to be searching the history, here we only care about the final state, so the oneline is sufficient.\n",
    "\n",
    "    df_XRBs['time'] = oneline_chunk['time_f'] * 1e-6 #Myr\n",
    "    df_XRBs['time_of_birth'] = oneline_chunk['time_i'] * 1e-6 #Myr\n",
    "    df_XRBs['metallicity'] = oneline_chunk['metallicity'] #This is not really necessary in our case, since we have one file per metallicity, but it is required by the fanctionality of the \"transient population we will use\"\n",
    "\n",
    "    # For the later calculations we are gonna do, it is convenient to switch from an S1 / S2 notation to donnor / accretor notation. \n",
    "    # To do that, we will loop over the systems and check which one is the compact object (BH or NS) and assign that to be the accretor, while the other star will be the donor.\n",
    "    # We will also store the type of compact object in a separate column.\n",
    "  \n",
    "    # Compact object types\n",
    "    compact_types = {'BH', 'NS'}\n",
    "\n",
    "    # Prepare new columns\n",
    "    donor_mass = []\n",
    "    accretor_mass = []\n",
    "    donor_state = []\n",
    "    accretor_state = []\n",
    "    donor_log_R = []\n",
    "    accretor_log_R = []\n",
    "    donor_lg_mdot = [] \n",
    "    accretor_lg_mdot = []\n",
    "    donor_surf_avg_omega_div_omega_crit = []\n",
    "    accretor_spin = []\n",
    "\n",
    "    Lx_rlo = []\n",
    "    Lx_bhl = []\n",
    "    Lx_tot = []\n",
    "\n",
    "    # Loop over each system\n",
    "    for s1, s2, m1, m2, logr1, logr2, mdot1, mdot2, omega1, omega2, spin1, spin2 in zip(oneline_chunk['S1_state_f'], oneline_chunk['S2_state_f'], oneline_chunk['S1_mass_f'], oneline_chunk['S2_mass_f'], oneline_chunk['S1_log_R_f'], oneline_chunk['S2_log_R_f'], oneline_chunk['S1_lg_mdot_f'], oneline_chunk['S2_lg_mdot_f'], oneline_chunk['S1_surf_avg_omega_div_omega_crit_f'], oneline_chunk['S2_surf_avg_omega_div_omega_crit_f'], oneline_chunk['S1_spin_f'], oneline_chunk['S2_spin_f']):\n",
    "        if s1 in compact_types and s2 not in compact_types:\n",
    "            accretor_mass.append(m1)\n",
    "            accretor_state.append(s1)\n",
    "            accretor_log_R.append(logr1)\n",
    "            accretor_lg_mdot.append(mdot1)\n",
    "            accretor_spin.append(spin1)\n",
    "            donor_mass.append(m2)\n",
    "            donor_state.append(s2)\n",
    "            donor_log_R.append(logr2)   \n",
    "            donor_lg_mdot.append(mdot2)\n",
    "            donor_surf_avg_omega_div_omega_crit.append(omega2)\n",
    "        elif s2 in compact_types and s1 not in compact_types:\n",
    "            accretor_mass.append(m2)\n",
    "            accretor_state.append(s2)\n",
    "            accretor_log_R.append(logr2)\n",
    "            accretor_lg_mdot.append(mdot2)\n",
    "            accretor_spin.append(spin2)\n",
    "            donor_mass.append(m1)\n",
    "            donor_state.append(s1)\n",
    "            donor_log_R.append(logr1)\n",
    "            donor_lg_mdot.append(mdot1)\n",
    "            donor_surf_avg_omega_div_omega_crit.append(omega1)\n",
    "        else:\n",
    "            # If neither or both are compact, fill with NaN or original values\n",
    "            accretor_mass.append(float('nan'))\n",
    "            accretor_state.append(None)\n",
    "            accretor_log_R.append(float('nan'))\n",
    "            accretor_lg_mdot.append(float('nan'))\n",
    "            accretor_spin.append(float('nan'))\n",
    "            donor_mass.append(float('nan'))\n",
    "            donor_state.append(None)\n",
    "            donor_log_R.append(float('nan'))\n",
    "            donor_lg_mdot.append(float('nan'))\n",
    "            donor_surf_avg_omega_div_omega_crit.append(float('nan'))\n",
    "\n",
    "    # Add new columns to DataFrame\n",
    "    df_XRBs['donor_mass'] = donor_mass\n",
    "    df_XRBs['accretor_mass'] = accretor_mass\n",
    "    df_XRBs['donor_state'] = donor_state\n",
    "    df_XRBs['accretor_state'] = accretor_state\n",
    "    df_XRBs['donor_log_R'] = donor_log_R\n",
    "    df_XRBs['accretor_log_R'] = accretor_log_R\n",
    "    df_XRBs['donor_lg_mdot'] = donor_lg_mdot\n",
    "    df_XRBs['accretor_lg_mdot'] = accretor_lg_mdot\n",
    "    df_XRBs['donor_surf_avg_omega_div_omega_crit'] = donor_surf_avg_omega_div_omega_crit\n",
    "    df_XRBs['accretor_spin'] = accretor_spin\n",
    "\n",
    "    # Finaly, add columns that are not associated to teh donor or the accretor\n",
    "    df_XRBs['orbital_period'] = oneline_chunk['orbital_period_f'].to_numpy()  # days\n",
    "    df_XRBs['eccentricity'] = oneline_chunk['eccentricity_f'] \n",
    "    df_XRBs['lg_mtransfer_rate'] = oneline_chunk['lg_mtransfer_rate_f'] #Msun/yr\n",
    "\n",
    "\n",
    "\n",
    "    for _, r in df_XRBs.iterrows():\n",
    "        Lx_RLO, Lx_BHL, Lx = compute_Lx_components(\n",
    "            donor_mass=r.get('donor_mass'),\n",
    "            donor_log_R=r.get('donor_log_R'),\n",
    "            accretor_mass=r.get('accretor_mass'),\n",
    "            accretor_type=r.get('accretor_state'),\n",
    "            lg_mtransfer_rate=r.get('lg_mtransfer_rate'),    # log10(Msun/yr)\n",
    "            donor_lg_mdot=r.get('donor_lg_mdot'),            # log10(Msun/yr), may include RLO\n",
    "            accretor_lg_mdot=r.get('accretor_lg_mdot'),      # log10(Msun/yr), includes only RLO\n",
    "            orbital_period_days=r.get('orbital_period'),\n",
    "            accretor_spin=r.get('accretor_spin'))\n",
    "        Lx_rlo.append(Lx_RLO)\n",
    "        Lx_bhl.append(Lx_BHL)\n",
    "        Lx_tot.append(Lx)\n",
    "    df_XRBs['Lx_rlo'] = Lx_rlo\n",
    "    df_XRBs['Lx_bhl'] = Lx_bhl\n",
    "    df_XRBs['Lx_tot'] = Lx_tot\n",
    "\n",
    "    return df_XRBs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d16bd",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "### Excercise 4\n",
    "Let's try our new selection function which include the X-ray luminosity function first on just one binary, and then to the entire population.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb710e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here your code for Excercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c2950",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "XRB_selection_function(XRB_pop.history[10], XRB_pop.oneline[10], None)\n",
    "\n",
    "XRBs = XRB_pop.create_transient_population(XRB_selection_function, 'XRB')\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69ac11",
   "metadata": {},
   "source": [
    "## 3. X-ray luminosity function (XLF) of extragalactic X-ray binaries  \n",
    "\n",
    "The **X-ray luminosity function (XLF)** of an extragalactic X-ray binary (XRB) population describes how many XRBs exist in a galaxy as a function of their X-ray luminosity. It can be expressed in two common forms:  \n",
    "\n",
    "- **Differential XLF**  \n",
    "  \n",
    "  $\\Phi(L_X) = \\frac{dN}{dL_X} \\quad \\text{or} \\quad \\frac{dN}{d\\log L_X}$\n",
    "\n",
    "  This gives the number of sources per unit luminosity (or per unit logarithmic luminosity bin).  \n",
    "\n",
    "- **Cumulative XLF**  \n",
    "  \n",
    "  $N(>L_X) = \\int_{L_X}^{\\infty} \\Phi(L)\\,dL$ \n",
    "  \n",
    "  This gives the total number of XRBs brighter than a given luminosity \\(L_X\\).  \n",
    "\n",
    "---\n",
    "\n",
    "### Observational usage  \n",
    "\n",
    "- In practice, **cumulative XLFs** are often shown because:  \n",
    "  - They avoid the statistical noise introduced by binning sparse data.  \n",
    "  - Power-law distributions appear as straight lines in logâ€“log space, making slopes easier to measure.  \n",
    "  - They allow easy comparison between galaxies with different numbers of detected sources.  \n",
    "\n",
    "---\n",
    "\n",
    "### Characteristic forms  \n",
    "\n",
    "- **High-mass XRBs (HMXBs)** in star-forming galaxies:  \n",
    "  - Cumulative XLF follows a nearly universal power law with slope \\(\\sim -0.6\\).  \n",
    "  - Normalization scales with the **star-formation rate**.  \n",
    "\n",
    "- **Low-mass XRBs (LMXBs)** in old populations:  \n",
    "  - Cumulative XLF shows a **break** at \\(L_X \\sim 10^{37-38}\\,\\text{erg/s}\\).  \n",
    "  - Normalization scales with the **stellar mass** of the host galaxy.  \n",
    "\n",
    "---\n",
    "\n",
    "ðŸ‘‰ When constructing an XLF from simulated POSYDON populations, you can examine either the **differential** or the **cumulative** form, but note that in most extragalactic studies the **cumulative XLF is the standard diagnostic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2244ee6",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "    \n",
    "### Excercise 5\n",
    "Create a a figure with the XLF of our XRB population. Use the total X-ray luminosity for each of the XRBs.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Hint (click to reveal):</summary></b>\n",
    "\n",
    "It maybe convenient to grab the relevant column from the XRB population object `XRBs.population['Lx_tot']` and convert it to an 1D numpy array, say L, to make the rest of the process easier.\n",
    "\n",
    "MESA often outputs -99 for for log values of quantities that are zero. We can filter those out, \n",
    "by setting a minimum value for the X-ray luminosity that we consider.\n",
    "\n",
    "The easiest way to compute an XLF is for the X axis to just sort the luminosities array, and for \n",
    "the Y axis to create an array of eual lenght to L, filled with ones, then use cumsum and finaly invert invert the order.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here your code for Excercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a53c7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "#Normally, on your own system where LateX is installed, you would load the posydon style like this:\n",
    "# import matplotlib as mpl\n",
    "# mpl.style.use(PATH_TO_POSYDON + 'posydon/visualization/posydon.mplstyle')\n",
    "\n",
    "# But since LateX may not be installed or configured properly on this system, \n",
    "# we will ignore the posydon style for now and just prevent LaTeX usage:\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['text.usetex'] = False  # prevent LaTeX usage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L = pd.to_numeric(XRBs.population['Lx_tot']).to_numpy(dtype=float)\n",
    "\n",
    "L_min = 1e30  # erg/s\n",
    "\n",
    "# MESA often outputs -99 for for log values of quantities that are zero. We can filter those out, \n",
    "# by setting a minimum value for the X-ray luminosity that we consider.\n",
    "L = L[(L > L_min)]\n",
    "\n",
    "# The easiest way to compute the cumulative distribution is to sort the luminosities \n",
    "# and then use cumsum and invert the order.\n",
    "L_sorted = np.sort(L)\n",
    "N_gt = np.cumsum(np.ones_like(L_sorted, dtype=int))[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "axs.step(L_sorted, N_gt)\n",
    "axs.set_xscale('log')\n",
    "axs.set_yscale('log')\n",
    "axs.set_xlabel('X-ray luminosity (erg/s)')\n",
    "axs.set_ylabel('N(>Lx)')\n",
    "axs.set_xlim(1e35, 1e40)\n",
    "axs.set_ylim(1, 1e2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "~~~~\n",
    "<details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb263f",
   "metadata": {},
   "source": [
    "### 3.1  A proper normalisation of our simulated XLF\n",
    "\n",
    "The Y axis of our XLF is rather arbitrary. Had we run a population of 10 times more binaries, we would have 10 times more XRBs. In order to compare with observations, it is best to normalise our XLF to something physical. For XLFs of star forming galaxies the normalisation of the Y axis is usually per unit of star formation rate $[M_\\odot/yr]$. \n",
    "\n",
    "In POSYDON, there is a function that gives us the probability of each of the modeled systems in our population per unit of stellar mass. This function function is very flexible allowing us to reweight these probabilities, for distributions of initial binary property distribution, different than the ones we had initially used in our population run. \n",
    "\n",
    "Here, we will use it in its simplest form. In our population run, we only modeled systems with primary masses above $5\\,\\rm M_\\odot$, as we did not want to waste cpu time to model binaries that we know would not form XRBs. However, in order to properly calculate the probability of each modeled binary per unit of stellar mass, we would need to extend the IMF of the primary, say down to $0.1\\,\\rm M_\\odot$. For the weights to be calculated properly, one needs to also redifine the limits for the mass ratio distribution: q_min and q_max. Here how this is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d987d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a copy of the initial population parameters and change the minimum primary mass to 0.1 Msun\n",
    "# This is needed for the reweighting to a full IMF down to low masses.\n",
    "pop_params = XRBs.ini_params.copy()\n",
    "\n",
    "pop_params['q_min'] = 0.0\n",
    "pop_params['q_max'] = 1.0\n",
    "pop_params['primary_mass_min'] = 0.1\n",
    "\n",
    "weights = XRBs.calculate_model_weights(model_weights_identifier=\"base_IMF\", population_parameters=pop_params)\n",
    "\n",
    "# These weights have unit of 1/Msun, and give the probability of each modeled system per unit of stellar mass formed in stars.\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbd7f9",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "### Excercise 6\n",
    "\n",
    "Let's now properly normalise our XLF, to be per unit of star formation rate. Remember that when we are talking about star formation rate in astronomy, there is always an implicit assumption about the starformation history of the population. The most common, and then one that we assume here is a constant star formation rate over the last 100 Myr. \n",
    "\n",
    "Use the weights we calculated above and our assumption of constant star formation rate over the last 100 Myr, to normalise our XLF.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Hint (click to reveal):</summary></b>\n",
    "\n",
    "Calculate how much stellar mass is formed over 100 My with a constant star formation of $1 M_\\odot / yr$ and multiply the calculated weight with this number. This will make them a proper uniteless weight.\n",
    "\n",
    "In the previous excercise, for the Y axis, you created an array of equal lenght to L, which you filled with ones. Now you should use the weights array instead.\n",
    "\n",
    "Don't forget to convert the weights to a numpy array as well.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here your code for Excercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2e7f8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "#Normally, on your own system where LateX is installed, you would load the posydon style like this:\n",
    "# import matplotlib as mpl\n",
    "# mpl.style.use(PATH_TO_POSYDON + 'posydon/visualization/posydon.mplstyle')\n",
    "\n",
    "# But since LateX may not be installed or configured properly on this system, \n",
    "# we will ignore the posydon style for now and just prevent LaTeX usage:\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['text.usetex'] = False  # prevent LaTeX usage\n",
    "\n",
    "\n",
    "Total_underlying_mass = 1e8 #Msun  -  1 Msolar/yr * 1e8 yr\n",
    "\n",
    "L = pd.to_numeric(XRBs.population['Lx_tot']).to_numpy(dtype=float)\n",
    "\n",
    "L_min = 1e30  # erg/s\n",
    "\n",
    "# MESA often outputs -99 for for log values of quantities that are zero. We can filter those out, \n",
    "# by setting a minimum value for the X-ray luminosity that we consider.\n",
    "L_masked = L[(L > L_min)]\n",
    "weights_masked = weights.to_numpy(dtype=float)[(L > L_min)]\n",
    "\n",
    "# The easiest way to compute the cumulative distribution is to sort the luminosities \n",
    "# and then use cumsum and invert the order.\n",
    "L_sorted = np.sort(L_masked)\n",
    "weights_sorted = weights_masked[np.argsort(L_masked)]\n",
    "N_gt = np.cumsum(weights_sorted)[::-1]* Total_underlying_mass\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "axs.step(L_sorted, N_gt)\n",
    "axs.set_xscale('log')\n",
    "axs.set_yscale('log')\n",
    "axs.set_xlabel('X-ray luminosity (erg/s)')\n",
    "axs.set_ylabel('N(>Lx)/SFR')\n",
    "axs.set_xlim(1e35, 1e40)\n",
    "axs.set_ylim(10, 2e3)\n",
    "plt.show()\n",
    "\n",
    "~~~\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d71b50",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "### Excercise 7\n",
    "\n",
    "Now, as a final excercise, let's try to explore a bit further the XLF by spliting it into subpopulations, depending on the type of the accretor (NS or BH), and the type of mass-transfer (RLO or wind-fed).\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c545f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here your code for Excercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397a13",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"margin-top: 20px\">\n",
    "<details>\n",
    "    \n",
    "<b><summary>Solution (click to reveal):</summary></b>\n",
    "\n",
    "~~~python\n",
    "\n",
    "Total_underlying_mass = 1e8 #Msun  -  1 Msolar/yr * 1e8 yr\n",
    "\n",
    "\n",
    "L_min = 1e30  # erg/s\n",
    "#mask_valid = np.isfinite(Lx_tot) & (Lx_tot > L_min)\n",
    "\n",
    "# Accretor type masks\n",
    "is_bh = XRBs.population['accretor_state'] == 'BH'\n",
    "is_ns = XRBs.population['accretor_state'] == 'NS'\n",
    "\n",
    "# Accretion mode masks\n",
    "# RLO if RLO luminosity > BHL luminosity\n",
    "is_rlo = (XRBs.population['Lx_rlo'] > XRBs.population['Lx_bhl']) & (XRBs.population['Lx_rlo'] > L_min)\n",
    "is_wind = (XRBs.population['Lx_rlo'] < XRBs.population['Lx_bhl']) & (XRBs.population['Lx_bhl'] > L_min)\n",
    "\n",
    "\n",
    "\n",
    "def plot_ccdf(vals, w, label):\n",
    "    x = np.sort(vals)                    # ascending\n",
    "    y = np.cumsum(w[np.argsort(vals)])[::-1]   # N(>x)\n",
    "    plt.step(x, y, where='post', label=label)\n",
    "\n",
    "plt.figure()\n",
    "plot_ccdf(XRBs.population.loc[is_rlo  & is_bh, 'Lx_tot'].to_numpy(), weights[is_rlo  & is_bh].to_numpy()*Total_underlying_mass, 'RLO + BH')\n",
    "plot_ccdf(XRBs.population.loc[is_rlo  & is_ns, 'Lx_tot'].to_numpy(), weights[is_rlo  & is_ns].to_numpy()*Total_underlying_mass, 'RLO + NS')\n",
    "plot_ccdf(XRBs.population.loc[is_wind & is_bh, 'Lx_tot'].to_numpy(), weights[is_wind & is_bh].to_numpy()*Total_underlying_mass, 'Wind + BH')\n",
    "plot_ccdf(XRBs.population.loc[is_wind & is_ns, 'Lx_tot'].to_numpy(), weights[is_wind & is_ns].to_numpy()*Total_underlying_mass, 'Wind + NS')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('X-ray luminosity (erg/s)')\n",
    "plt.ylabel('N(>Lx)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "~~~\n",
    "\n",
    "<details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91efde77",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "    \n",
    "### (Optional) Excercise 8\n",
    "\n",
    "Compare your simulated XLFs and observed on, e.g. Figure 3 in [Lehmer et al. (2021)](https://arxiv.org/pdf/2011.09476). Do you see any similarities? Do you see any obvious discrepancies? In Figure 3 of [Lehmer et al. (2021)](https://arxiv.org/pdf/2011.09476) you also see the dependence of the XLF to metallicity. You can load a second populations that is available to you at 10% Solar metallicity and see if a similar trend appears in your simulated XLFs. Can you speculate what might be the reason of the dependence of the XLF shape to metallicity?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264048df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POSYDON (2.1.6)",
   "language": "python",
   "name": "posydon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
